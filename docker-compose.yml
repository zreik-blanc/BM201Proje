services:
  llm-server:
    build: ./server
    container_name: websocket_server
    restart: unless-stopped
    expose:
      - "8000"
    volumes:
      - ./server:/app
    env_file:
      - ./server/.env
    # dont forget to remove --reload in demo showcase
    command: [ "uvicorn", "app.main:app", "--host", "0.0.0.0", "--port", "8000", "--reload" ]

  nginx:
    image: nginx:latest
    container_name: nginx_proxy
    restart: unless-stopped
    volumes:
      - ./server/nginx/nginx.conf:/etc/nginx/nginx.conf:ro
    ports:
      - "80:80"
    depends_on:
      - llm-server